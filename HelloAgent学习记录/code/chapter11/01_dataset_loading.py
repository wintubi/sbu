"""
ç¤ºä¾‹1: æ•°æ®é›†åŠ è½½å’Œæ ¼å¼åŒ–
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨RLTrainingToolåŠ è½½å’ŒæŸ¥çœ‹GSM8Kæ•°æ®é›†
"""

import sys
from pathlib import Path
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent / "HelloAgents"
sys.path.insert(0, str(project_root))

from hello_agents.tools import RLTrainingTool


# ============================================================================
# ç¤ºä¾‹1: åŠ è½½SFTæ ¼å¼æ•°æ®é›†
# ============================================================================

def load_sft_dataset():
    """
    ä½¿ç”¨RLTrainingToolåŠ è½½SFTæ ¼å¼çš„GSM8Kæ•°æ®é›†

    SFTæ•°æ®æ ¼å¼:
    {
        "prompt": "Question: ...\n\nLet's solve this step by step:\n",
        "completion": "Step 1: ...\nFinal Answer: 42",
        "text": "Question: ...\n\nLet's solve this step by step:\nStep 1: ...\nFinal Answer: 42"
    }
    """
    tool = RLTrainingTool()

    config = {
        "action": "load_dataset",
        "format": "sft",
        "split": "train",
        "max_samples": 5
    }

    print("åŠ è½½SFTæ ¼å¼æ•°æ®é›†...")
    result = tool.run(config)
    result_dict = json.loads(result)

    print(f"âœ… æ•°æ®é›†å¤§å°: {result_dict['dataset_size']}")
    print(f"ğŸ“‹ æ•°æ®é›†åˆ—: {result_dict['sample_keys']}")
    print(f"\nğŸ’¡ æç¤º: æ•°æ®é›†å·²åŠ è½½,å¯ä»¥ç”¨äºè®­ç»ƒ")
    print(f"   ä½¿ç”¨ action='train' å¼€å§‹è®­ç»ƒ")

    return result_dict


# ============================================================================
# ç¤ºä¾‹2: åŠ è½½RLæ ¼å¼æ•°æ®é›†
# ============================================================================

def load_rl_dataset():
    """
    ä½¿ç”¨RLTrainingToolåŠ è½½RLæ ¼å¼çš„GSM8Kæ•°æ®é›†

    RLæ•°æ®æ ¼å¼:
    {
        "prompt": "<|im_start|>user\nQuestion: ...\n<|im_end|>\n<|im_start|>assistant\n",
        "ground_truth": "42",
        "question": "...",
        "full_answer": "..."
    }
    """
    tool = RLTrainingTool()

    config = {
        "action": "load_dataset",
        "format": "rl",
        "split": "train",
        "max_samples": 5,
        "model_name": "Qwen/Qwen3-0.6B"
    }

    print("åŠ è½½RLæ ¼å¼æ•°æ®é›†...")
    result = tool.run(config)
    result_dict = json.loads(result)

    print(f"âœ… æ•°æ®é›†å¤§å°: {result_dict['dataset_size']}")
    print(f"ğŸ“‹ æ•°æ®é›†åˆ—: {result_dict['sample_keys']}")
    print(f"\nğŸ’¡ æç¤º: RLæ•°æ®é›†å·²åŠ è½½,åŒ…å«promptå’Œground_truth")
    print(f"   å¯ç”¨äºGRPOè®­ç»ƒ")

    return result_dict


# ============================================================================
# ç¤ºä¾‹3: åŠ è½½ä¸åŒsplitçš„æ•°æ®é›†
# ============================================================================

def load_different_splits():
    """
    åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    """
    tool = RLTrainingTool()
    
    # åŠ è½½è®­ç»ƒé›†
    train_config = {
        "action": "load_dataset",
        "format": "sft",
        "split": "train",
        "max_samples": 100
    }
    
    print("åŠ è½½è®­ç»ƒé›†...")
    train_result = tool.run(train_config)
    train_data = json.loads(train_result)
    print(f"âœ… è®­ç»ƒé›†: {train_data['dataset_size']} æ ·æœ¬")
    
    # åŠ è½½æµ‹è¯•é›†
    test_config = {
        "action": "load_dataset",
        "format": "sft",
        "split": "test",
        "max_samples": 50
    }
    
    print("\nåŠ è½½æµ‹è¯•é›†...")
    test_result = tool.run(test_config)
    test_data = json.loads(test_result)
    print(f"âœ… æµ‹è¯•é›†: {test_data['dataset_size']} æ ·æœ¬")
    
    return train_data, test_data


# ============================================================================
# ç¤ºä¾‹4: åŠ è½½å®Œæ•´æ•°æ®é›†
# ============================================================================

def load_full_dataset():
    """
    åŠ è½½å®Œæ•´æ•°æ®é›† (max_samples=None)
    
    GSM8Kæ•°æ®é›†:
    - è®­ç»ƒé›†: ~7500 æ ·æœ¬
    - æµ‹è¯•é›†: ~1300 æ ·æœ¬
    """
    tool = RLTrainingTool()
    
    config = {
        "action": "load_dataset",
        "format": "sft",
        "split": "train",
        "max_samples": None  # None = ä½¿ç”¨å…¨éƒ¨æ•°æ®
    }
    
    print("åŠ è½½å®Œæ•´è®­ç»ƒé›†...")
    print("âš ï¸  è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
    
    # å®é™…åŠ è½½æ—¶å–æ¶ˆæ³¨é‡Š
    # result = tool.run(config)
    # result_dict = json.loads(result)
    # print(f"âœ… å®Œæ•´è®­ç»ƒé›†: {result_dict['dataset_size']} æ ·æœ¬")
    
    print("ğŸ’¡ æç¤º: è®¾ç½® max_samples=None å¯ä»¥åŠ è½½å…¨éƒ¨æ•°æ®")
    print("   GSM8Kè®­ç»ƒé›†çº¦æœ‰ 7500 ä¸ªæ ·æœ¬")
    
    return config


# ============================================================================
# ç¤ºä¾‹5: å¯¹æ¯”SFTå’ŒRLæ ¼å¼
# ============================================================================

def compare_sft_rl_formats():
    """
    å¯¹æ¯”SFTå’ŒRLæ•°æ®æ ¼å¼çš„åŒºåˆ«
    """
    tool = RLTrainingTool()

    print("="*80)
    print("SFT vs RL æ•°æ®æ ¼å¼å¯¹æ¯”")
    print("="*80)

    # SFTæ ¼å¼
    sft_config = {
        "action": "load_dataset",
        "format": "sft",
        "split": "train",
        "max_samples": 1
    }

    print("\n1. SFTæ ¼å¼:")
    sft_result = tool.run(sft_config)
    sft_data = json.loads(sft_result)
    print(f"   åˆ—: {sft_data['sample_keys']}")
    print(f"   ç”¨é€”: ç›‘ç£å¾®è°ƒ (Supervised Fine-Tuning)")
    print(f"   ç‰¹ç‚¹: åŒ…å«å®Œæ•´çš„promptå’Œcompletion")

    # RLæ ¼å¼
    rl_config = {
        "action": "load_dataset",
        "format": "rl",
        "split": "train",
        "max_samples": 1,
        "model_name": "Qwen/Qwen3-0.6B"
    }

    print("\n2. RLæ ¼å¼:")
    rl_result = tool.run(rl_config)
    rl_data = json.loads(rl_result)
    print(f"   åˆ—: {rl_data['sample_keys']}")
    print(f"   ç”¨é€”: å¼ºåŒ–å­¦ä¹ è®­ç»ƒ (Reinforcement Learning)")
    print(f"   ç‰¹ç‚¹: åŒ…å«promptå’Œground_truth,ç”¨äºå¥–åŠ±è®¡ç®—")

    print("\nä¸»è¦åŒºåˆ«:")
    print("  - SFT: ç›´æ¥å­¦ä¹ æ­£ç¡®ç­”æ¡ˆ")
    print("  - RL: é€šè¿‡å¥–åŠ±ä¿¡å·å­¦ä¹ ,æ›´çµæ´»")

    return sft_data, rl_data


# ============================================================================
# ç¤ºä¾‹6: æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
# ============================================================================

def dataset_statistics():
    """
    æŸ¥çœ‹æ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯
    """
    tool = RLTrainingTool()

    config = {
        "action": "load_dataset",
        "format": "sft",
        "split": "train",
        "max_samples": 100
    }

    print("åŠ è½½æ•°æ®é›†...")
    result = tool.run(config)
    result_dict = json.loads(result)

    print("\næ•°æ®é›†ç»Ÿè®¡:")
    print(f"  æ€»æ ·æœ¬æ•°: {result_dict['dataset_size']}")
    print(f"  æ•°æ®åˆ—: {', '.join(result_dict['sample_keys'])}")
    print(f"  æ•°æ®é›†: GSM8K (Grade School Math 8K)")
    print(f"  ä»»åŠ¡ç±»å‹: æ•°å­¦æ¨ç†")

    print(f"\nğŸ’¡ æç¤º: æ•°æ®é›†åŒ…å«ä»¥ä¸‹å­—æ®µ:")
    for key in result_dict['sample_keys']:
        print(f"  - {key}")

    return result_dict


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

if __name__ == "__main__":
    print("="*80)
    print("ç¤ºä¾‹1: åŠ è½½SFTæ ¼å¼æ•°æ®é›†")
    print("="*80)
    load_sft_dataset()
    
    print("\n" + "="*80)
    print("ç¤ºä¾‹2: åŠ è½½RLæ ¼å¼æ•°æ®é›†")
    print("="*80)
    load_rl_dataset()
    
    print("\n" + "="*80)
    print("ç¤ºä¾‹3: åŠ è½½ä¸åŒsplitçš„æ•°æ®é›†")
    print("="*80)
    load_different_splits()
    
    print("\n" + "="*80)
    print("ç¤ºä¾‹4: åŠ è½½å®Œæ•´æ•°æ®é›†")
    print("="*80)
    load_full_dataset()
    
    print("\n" + "="*80)
    print("ç¤ºä¾‹5: å¯¹æ¯”SFTå’ŒRLæ ¼å¼")
    print("="*80)
    compare_sft_rl_formats()
    
    print("\n" + "="*80)
    print("ç¤ºä¾‹6: æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯")
    print("="*80)
    dataset_statistics()

