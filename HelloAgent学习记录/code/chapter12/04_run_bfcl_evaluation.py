"""
ç¬¬åäºŒç« ï¼šBFCLä¸€é”®è¯„ä¼°è„šæœ¬

æœ¬è„šæœ¬æä¾›å®Œæ•´çš„BFCLè¯„ä¼°æµç¨‹ï¼š
1. è‡ªåŠ¨æ£€æŸ¥å’Œå‡†å¤‡BFCLæ•°æ®
2. è¿è¡ŒHelloAgentsè¯„ä¼°
3. å¯¼å‡ºBFCLæ ¼å¼ç»“æœ
4. è°ƒç”¨BFCLå®˜æ–¹è¯„ä¼°å·¥å…·
5. å±•ç¤ºè¯„ä¼°ç»“æœ

ä½¿ç”¨æ–¹æ³•ï¼š
    python examples/04_run_bfcl_evaluation.py

å¯é€‰å‚æ•°ï¼š
    --category: è¯„ä¼°ç±»åˆ«ï¼ˆé»˜è®¤ï¼šsimple_pythonï¼‰
    --samples: æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤ï¼š5ï¼Œè®¾ä¸º0è¡¨ç¤ºå…¨éƒ¨ï¼‰
    --model-name: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šHelloAgentsï¼‰
"""

import sys
import subprocess
from pathlib import Path
import argparse
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from hello_agents import SimpleAgent, HelloAgentsLLM
from hello_agents.evaluation import BFCLDataset, BFCLEvaluator


# å‡½æ•°è°ƒç”¨ç³»ç»Ÿæç¤ºè¯
FUNCTION_CALLING_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‡½æ•°è°ƒç”¨åŠ©æ‰‹ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼šæ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œæä¾›çš„å‡½æ•°å®šä¹‰ï¼Œç”Ÿæˆæ­£ç¡®çš„å‡½æ•°è°ƒç”¨ã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1. å¿…é¡»æ˜¯çº¯JSONæ ¼å¼ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—
2. ä½¿ç”¨JSONæ•°ç»„æ ¼å¼ï¼š[{"name": "å‡½æ•°å", "arguments": {"å‚æ•°å": "å‚æ•°å€¼"}}]
3. å¦‚æœéœ€è¦è°ƒç”¨å¤šä¸ªå‡½æ•°ï¼Œåœ¨æ•°ç»„ä¸­æ·»åŠ å¤šä¸ªå¯¹è±¡
4. å¦‚æœä¸éœ€è¦è°ƒç”¨å‡½æ•°ï¼Œè¿”å›ç©ºæ•°ç»„ï¼š[]

ç¤ºä¾‹ï¼š
ç”¨æˆ·é—®é¢˜ï¼šæŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”
å¯ç”¨å‡½æ•°ï¼šget_weather(city: str)
æ­£ç¡®è¾“å‡ºï¼š[{"name": "get_weather", "arguments": {"city": "åŒ—äº¬"}}]

æ³¨æ„ï¼š
- åªè¾“å‡ºJSONï¼Œä¸è¦æ·»åŠ "å¥½çš„"ã€"æˆ‘æ¥å¸®ä½ "ç­‰é¢å¤–æ–‡å­—
- å‚æ•°å€¼å¿…é¡»ä¸å‡½æ•°å®šä¹‰çš„ç±»å‹åŒ¹é…
- å‚æ•°åå¿…é¡»ä¸å‡½æ•°å®šä¹‰å®Œå…¨ä¸€è‡´
"""


def check_bfcl_data(bfcl_data_dir: Path) -> bool:
    """æ£€æŸ¥BFCLæ•°æ®æ˜¯å¦å­˜åœ¨"""
    if not bfcl_data_dir.exists():
        print(f"\nâŒ BFCLæ•°æ®ç›®å½•ä¸å­˜åœ¨: {bfcl_data_dir}")
        print(f"\nè¯·å…ˆå…‹éš†BFCLä»“åº“ï¼š")
        print(f"   git clone --depth 1 https://github.com/ShishirPatil/gorilla.git temp_gorilla")
        return False
    return True


def run_evaluation(category: str, max_samples: int, model_name: str) -> dict:
    """è¿è¡ŒHelloAgentsè¯„ä¼°"""
    print("\n" + "="*60)
    print("æ­¥éª¤1: è¿è¡ŒHelloAgentsè¯„ä¼°")
    print("="*60)
    
    # BFCLæ•°æ®ç›®å½•
    bfcl_data_dir = project_root / "temp_gorilla" / "berkeley-function-call-leaderboard" / "bfcl_eval" / "data"
    
    # æ£€æŸ¥æ•°æ®
    if not check_bfcl_data(bfcl_data_dir):
        return None
    
    # åŠ è½½æ•°æ®é›†
    print(f"\nğŸ“š åŠ è½½BFCLæ•°æ®é›†...")
    dataset = BFCLDataset(bfcl_data_dir=str(bfcl_data_dir), category=category)

    # åˆ›å»ºæ™ºèƒ½ä½“
    print(f"\nğŸ¤– åˆ›å»ºæ™ºèƒ½ä½“...")
    llm = HelloAgentsLLM()
    agent = SimpleAgent(
        name=model_name,
        llm=llm,
        system_prompt=FUNCTION_CALLING_SYSTEM_PROMPT,
        enable_tool_calling=False
    )
    print(f"   æ™ºèƒ½ä½“: {model_name}")
    print(f"   LLM: {llm.provider}")

    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = BFCLEvaluator(dataset=dataset, category=category)

    # è¿è¡Œè¯„ä¼°ï¼ˆä¼ é€’max_sampleså‚æ•°ï¼‰
    print(f"\nğŸ”„ å¼€å§‹è¯„ä¼°...")
    if max_samples > 0:
        print(f"   æ ·æœ¬æ•°é‡: {max_samples}")
        results = evaluator.evaluate(agent, max_samples=max_samples)
    else:
        print(f"   æ ·æœ¬æ•°é‡: å…¨éƒ¨")
        results = evaluator.evaluate(agent, max_samples=None)
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"   å‡†ç¡®ç‡: {results['overall_accuracy']:.2%}")
    print(f"   æ­£ç¡®æ•°: {results['correct_samples']}/{results['total_samples']}")
    
    return results


def export_bfcl_format(results: dict, category: str, model_name: str) -> Path:
    """å¯¼å‡ºBFCLæ ¼å¼ç»“æœ"""
    print("\n" + "="*60)
    print("æ­¥éª¤2: å¯¼å‡ºBFCLæ ¼å¼ç»“æœ")
    print("="*60)
    
    # è¾“å‡ºç›®å½•
    output_dir = project_root / "evaluation_results" / "bfcl_official"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¾“å‡ºæ–‡ä»¶
    output_file = output_dir / f"BFCL_v4_{category}_result.json"
    
    # åˆ›å»ºè¯„ä¼°å™¨ï¼ˆç”¨äºå¯¼å‡ºï¼‰
    bfcl_data_dir = project_root / "temp_gorilla" / "berkeley-function-call-leaderboard" / "bfcl_eval" / "data"
    dataset = BFCLDataset(bfcl_data_dir=str(bfcl_data_dir), category=category)
    evaluator = BFCLEvaluator(dataset=dataset, category=category)
    
    # å¯¼å‡º
    evaluator.export_to_bfcl_format(results, output_file)
    
    return output_file


def copy_to_bfcl_result_dir(source_file: Path, model_name: str, category: str) -> Path:
    """å¤åˆ¶ç»“æœæ–‡ä»¶åˆ°BFCLç»“æœç›®å½•"""
    print("\n" + "="*60)
    print("æ­¥éª¤3: å‡†å¤‡BFCLå®˜æ–¹è¯„ä¼°")
    print("="*60)
    
    # BFCLç»“æœç›®å½•
    # æ³¨æ„ï¼šBFCLä¼šå°†æ¨¡å‹åä¸­çš„"/"æ›¿æ¢ä¸º"_"
    safe_model_name = model_name.replace("/", "_")
    result_dir = project_root / "result" / safe_model_name
    result_dir.mkdir(parents=True, exist_ok=True)
    
    # ç›®æ ‡æ–‡ä»¶
    target_file = result_dir / f"BFCL_v4_{category}_result.json"
    
    # å¤åˆ¶æ–‡ä»¶
    import shutil
    shutil.copy(source_file, target_file)
    
    print(f"\nâœ… ç»“æœæ–‡ä»¶å·²å¤åˆ¶åˆ°:")
    print(f"   {target_file}")
    
    return target_file


def run_bfcl_official_eval(model_name: str, category: str) -> bool:
    """è¿è¡ŒBFCLå®˜æ–¹è¯„ä¼°"""
    print("\n" + "="*60)
    print("æ­¥éª¤4: è¿è¡ŒBFCLå®˜æ–¹è¯„ä¼°")
    print("="*60)
    
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        import os
        os.environ['PYTHONUTF8'] = '1'
        
        # è¿è¡ŒBFCLè¯„ä¼°
        cmd = [
            "bfcl", "evaluate",
            "--model", model_name,
            "--test-category", category,
            "--partial-eval"
        ]
        
        print(f"\nğŸ”„ è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        result = subprocess.run(
            cmd,
            cwd=str(project_root),
            capture_output=True,
            text=True,
            encoding='utf-8'
        )
        
        # æ˜¾ç¤ºè¾“å‡º
        if result.stdout:
            print(result.stdout)
        
        if result.returncode != 0:
            print(f"\nâŒ BFCLè¯„ä¼°å¤±è´¥:")
            if result.stderr:
                print(result.stderr)
            return False
        
        return True
        
    except FileNotFoundError:
        print("\nâŒ æœªæ‰¾åˆ°bfclå‘½ä»¤")
        print("   è¯·å…ˆå®‰è£…: pip install bfcl-eval")
        return False
    except Exception as e:
        print(f"\nâŒ è¿è¡ŒBFCLè¯„ä¼°æ—¶å‡ºé”™: {e}")
        return False


def show_results(model_name: str, category: str):
    """å±•ç¤ºè¯„ä¼°ç»“æœ"""
    print("\n" + "="*60)
    print("æ­¥éª¤5: å±•ç¤ºè¯„ä¼°ç»“æœ")
    print("="*60)
    
    # CSVæ–‡ä»¶
    csv_file = project_root / "score" / "data_non_live.csv"
    
    if csv_file.exists():
        print(f"\nğŸ“Š è¯„ä¼°ç»“æœæ±‡æ€»:")
        with open(csv_file, 'r', encoding='utf-8') as f:
            content = f.read()
            print(content)
    else:
        print(f"\nâš ï¸ æœªæ‰¾åˆ°è¯„ä¼°ç»“æœæ–‡ä»¶: {csv_file}")
    
    # è¯¦ç»†è¯„åˆ†æ–‡ä»¶
    safe_model_name = model_name.replace("/", "_")
    score_file = project_root / "score" / safe_model_name / "non_live" / f"BFCL_v4_{category}_score.json"
    
    if score_file.exists():
        print(f"\nğŸ“ è¯¦ç»†è¯„åˆ†æ–‡ä»¶:")
        print(f"   {score_file}")
        
        # è¯»å–å¹¶æ˜¾ç¤ºå‡†ç¡®ç‡
        with open(score_file, 'r', encoding='utf-8') as f:
            first_line = f.readline()
            summary = json.loads(first_line)
            print(f"\nğŸ¯ æœ€ç»ˆç»“æœ:")
            print(f"   å‡†ç¡®ç‡: {summary['accuracy']:.2%}")
            print(f"   æ­£ç¡®æ•°: {summary['correct_count']}/{summary['total_count']}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="BFCLä¸€é”®è¯„ä¼°è„šæœ¬")
    parser.add_argument("--category", default="simple_python", help="è¯„ä¼°ç±»åˆ«")
    parser.add_argument("--samples", type=int, default=5, help="æ ·æœ¬æ•°é‡ï¼ˆ0è¡¨ç¤ºå…¨éƒ¨ï¼‰")
    parser.add_argument("--model-name", default="Qwen/Qwen3-8B",
                       help="æ¨¡å‹åç§°ï¼ˆå¿…é¡»æ˜¯BFCLæ”¯æŒçš„æ¨¡å‹ï¼Œè¿è¡Œ'bfcl models'æŸ¥çœ‹ï¼‰")
    
    args = parser.parse_args()
    
    print("="*60)
    print("BFCLä¸€é”®è¯„ä¼°è„šæœ¬")
    print("="*60)
    print(f"\né…ç½®:")
    print(f"   è¯„ä¼°ç±»åˆ«: {args.category}")
    print(f"   æ ·æœ¬æ•°é‡: {args.samples if args.samples > 0 else 'å…¨éƒ¨'}")
    print(f"   æ¨¡å‹åç§°: {args.model_name}")
    
    # æ­¥éª¤1: è¿è¡Œè¯„ä¼°
    results = run_evaluation(args.category, args.samples, args.model_name)
    if not results:
        return
    
    # æ­¥éª¤2: å¯¼å‡ºBFCLæ ¼å¼
    output_file = export_bfcl_format(results, args.category, args.model_name)
    
    # æ­¥éª¤3: å¤åˆ¶åˆ°BFCLç»“æœç›®å½•
    copy_to_bfcl_result_dir(output_file, args.model_name, args.category)
    
    # æ­¥éª¤4: è¿è¡ŒBFCLå®˜æ–¹è¯„ä¼°
    if not run_bfcl_official_eval(args.model_name, args.category):
        print("\nâš ï¸ BFCLå®˜æ–¹è¯„ä¼°å¤±è´¥ï¼Œä½†HelloAgentsè¯„ä¼°å·²å®Œæˆ")
        return
    
    # æ­¥éª¤5: å±•ç¤ºç»“æœ
    show_results(args.model_name, args.category)
    
    print("\n" + "="*60)
    print("âœ… è¯„ä¼°å®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    main()

