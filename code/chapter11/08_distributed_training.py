"""
åˆ†å¸ƒå¼è®­ç»ƒç¤ºä¾‹

æœ¬è„šæœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Accelerateè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚
è®­ç»ƒä»£ç æœ¬èº«æ— éœ€ä¿®æ”¹,åªéœ€é€šè¿‡accelerate launchå¯åŠ¨å³å¯ã€‚

ä½¿ç”¨æ–¹æ³•:
1. å•GPUè®­ç»ƒ:
   python 07_distributed_training.py

2. å¤šGPU DDPè®­ç»ƒ:
   accelerate launch --config_file accelerate_configs/multi_gpu_ddp.yaml 07_distributed_training.py

3. DeepSpeed ZeRO-2è®­ç»ƒ:
   accelerate launch --config_file accelerate_configs/deepspeed_zero2.yaml 07_distributed_training.py

4. DeepSpeed ZeRO-3è®­ç»ƒ:
   accelerate launch --config_file accelerate_configs/deepspeed_zero3.yaml 07_distributed_training.py
"""

import sys
import os

# æ·»åŠ HelloAgentsåˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "HelloAgents"))

from hello_agents.tools import RLTrainingTool
import json

def main():
    print("="*80)
    print("åˆ†å¸ƒå¼è®­ç»ƒç¤ºä¾‹")
    print("="*80)
    
    # æ£€æµ‹åˆ†å¸ƒå¼ç¯å¢ƒ
    world_size = int(os.environ.get("WORLD_SIZE", 1))
    local_rank = int(os.environ.get("LOCAL_RANK", 0))
    
    if world_size > 1:
        print(f"\nğŸš€ åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼")
        print(f"   - æ€»è¿›ç¨‹æ•°: {world_size}")
        print(f"   - å½“å‰è¿›ç¨‹: {local_rank}")
        print(f"   - åˆ†å¸ƒå¼åç«¯: {os.environ.get('ACCELERATE_DISTRIBUTED_TYPE', 'MULTI_GPU')}")
    else:
        print(f"\nğŸ’» å•GPUè®­ç»ƒæ¨¡å¼")
    
    print("="*80)
    
    # åˆ›å»ºè®­ç»ƒå·¥å…·
    rl_tool = RLTrainingTool()
    
    # è®­ç»ƒé…ç½®
    # æ³¨æ„: batch_sizeæ˜¯æ¯ä¸ªGPUçš„batch size
    # æ€»batch size = batch_size Ã— num_gpus Ã— gradient_accumulation_steps
    config = {
        "action": "train",
        "algorithm": "grpo",
        "model_name": "Qwen/Qwen3-0.6B",
        "output_dir": "./models/grpo_distributed",
        "max_samples": 200,  # ä½¿ç”¨200ä¸ªæ ·æœ¬
        "num_epochs": 2,
        "batch_size": 2,  # æ¯ä¸ªGPUçš„batch size
        "use_lora": True,
        "use_wandb": False,
        "use_tensorboard": True,
    }
    
    # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°é…ç½®
    if local_rank == 0:
        print("\nè®­ç»ƒé…ç½®:")
        print(f"  - æ¨¡å‹: {config['model_name']}")
        print(f"  - æ ·æœ¬æ•°: {config['max_samples']}")
        print(f"  - Epochæ•°: {config['num_epochs']}")
        print(f"  - æ¯GPU batch size: {config['batch_size']}")
        if world_size > 1:
            total_batch = config['batch_size'] * world_size
            print(f"  - æ€»batch size: {total_batch}")
        print("="*80)
    
    # å¼€å§‹è®­ç»ƒ
    # è®­ç»ƒä»£ç å®Œå…¨ä¸éœ€è¦ä¿®æ”¹!
    # Accelerateä¼šè‡ªåŠ¨å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒçš„æ‰€æœ‰ç»†èŠ‚
    result = rl_tool.run(config)
    
    # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°ç»“æœ
    if local_rank == 0:
        result_data = json.loads(result)
        print("\n" + "="*80)
        print("è®­ç»ƒå®Œæˆ!")
        print("="*80)
        print(f"çŠ¶æ€: {result_data['status']}")
        print(f"æ¨¡å‹è·¯å¾„: {result_data['output_dir']}")
        print("="*80)
        
        # æ‰“å°æ€§èƒ½æç¤º
        if world_size > 1:
            print(f"\nğŸ’¡ æ€§èƒ½æç¤º:")
            print(f"   ä½¿ç”¨äº† {world_size} ä¸ªGPUè¿›è¡Œè®­ç»ƒ")
            print(f"   ç†è®ºåŠ é€Ÿæ¯”: ~{world_size * 0.85:.1f}x")
            print(f"   (å®é™…åŠ é€Ÿæ¯”å–å†³äºé€šä¿¡å¼€é”€å’Œæ•°æ®åŠ è½½)")

if __name__ == "__main__":
    main()

